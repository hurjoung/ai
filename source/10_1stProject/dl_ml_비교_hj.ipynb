{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3472be08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 정확도 비교 (일 매출 AMT_sum) ===\n",
      "RandomForest  MAE=17,858,319  R2=0.724\n",
      "DeepLearning  MAE=176,169,782  R2=-10.910\n",
      "\n",
      "Saved images:\n",
      "- accuracy_bar_mae.png\n",
      "- accuracy_bar_r2.png\n",
      "- pred_scatter.png\n",
      "- residual_hist.png\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# =========================\n",
    "# 1) 데이터 로드 & 일별 집계\n",
    "# =========================\n",
    "CSV_PATH = \"SUWON_S_DATA_TABLE_GENDER_SUM.csv\"\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "df[\"TA_YMD\"] = pd.to_datetime(df[\"TA_YMD\"], format=\"%Y%m%d\")\n",
    "\n",
    "daily = df.groupby(\"TA_YMD\", as_index=False).agg(\n",
    "    AMT_sum=(\"AMT\", \"sum\"),\n",
    "    TEMP_mean=(\"TEMP\", \"mean\"),\n",
    "    RAIN_sum=(\"RAIN\", \"sum\"),\n",
    "    DAY_mode=(\"DAY\", lambda x: int(pd.Series(x).mode()[0])),\n",
    ")\n",
    "daily[\"month\"] = daily[\"TA_YMD\"].dt.month\n",
    "daily = daily.sort_values(\"TA_YMD\").reset_index(drop=True)\n",
    "\n",
    "# ✅ 공정 비교: 시간순 split (과거 80% / 미래 20%)\n",
    "split = int(len(daily) * 0.8)\n",
    "train_df = daily.iloc[:split].copy()\n",
    "test_df  = daily.iloc[split:].copy()\n",
    "\n",
    "X_train = train_df[[\"DAY_mode\", \"TEMP_mean\", \"RAIN_sum\", \"month\"]]\n",
    "y_train = train_df[\"AMT_sum\"].values\n",
    "X_test  = test_df[[\"DAY_mode\", \"TEMP_mean\", \"RAIN_sum\", \"month\"]]\n",
    "y_test  = test_df[\"AMT_sum\"].values\n",
    "\n",
    "# =========================\n",
    "# 2) 머신러닝: RandomForest\n",
    "# =========================\n",
    "preprocess = ColumnTransformer([\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), [\"DAY_mode\"]),\n",
    "    (\"num\", \"passthrough\", [\"TEMP_mean\", \"RAIN_sum\", \"month\"]),\n",
    "])\n",
    "\n",
    "rf = Pipeline([\n",
    "    (\"prep\", preprocess),\n",
    "    (\"rf\", RandomForestRegressor(\n",
    "        n_estimators=600,\n",
    "        max_depth=12,\n",
    "        min_samples_leaf=2,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "\n",
    "rf_mae = mean_absolute_error(y_test, rf_pred)\n",
    "rf_r2  = r2_score(y_test, rf_pred)\n",
    "\n",
    "# =========================\n",
    "# 3) 딥러닝: TabTransformer-style (PyTorch)\n",
    "# =========================\n",
    "class TabDataset(Dataset):\n",
    "    def __init__(self, x_cat, x_num, y):\n",
    "        self.x_cat = torch.tensor(x_cat, dtype=torch.long)\n",
    "        self.x_num = torch.tensor(x_num, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32).view(-1, 1)\n",
    "    def __len__(self): return len(self.y)\n",
    "    def __getitem__(self, idx): return self.x_cat[idx], self.x_num[idx], self.y[idx]\n",
    "\n",
    "class SimpleTabTransformer(nn.Module):\n",
    "    def __init__(self, emb_dim=16, nhead=4, nlayers=2, ff=128, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.day_emb = nn.Embedding(7, emb_dim)\n",
    "        self.mon_emb = nn.Embedding(12, emb_dim)\n",
    "        enc = nn.TransformerEncoderLayer(\n",
    "            d_model=emb_dim, nhead=nhead, dim_feedforward=ff, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.tr = nn.TransformerEncoder(enc, num_layers=nlayers)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(emb_dim + 2, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "    def forward(self, x_cat, x_num):\n",
    "        tokens = torch.stack([self.day_emb(x_cat[:,0]), self.mon_emb(x_cat[:,1])], dim=1)  # (B,2,emb)\n",
    "        z = self.tr(tokens).mean(dim=1)\n",
    "        return self.mlp(torch.cat([z, x_num], dim=1))\n",
    "\n",
    "def encode(df_):\n",
    "    day = (df_[\"DAY_mode\"].astype(int).clip(1,7) - 1).values\n",
    "    mon = (df_[\"month\"].astype(int).clip(1,12) - 1).values\n",
    "    x_cat = np.vstack([day, mon]).T\n",
    "    x_num = df_[[\"TEMP_mean\", \"RAIN_sum\"]].values.astype(np.float32)\n",
    "    y = df_[\"AMT_sum\"].values.astype(np.float32)\n",
    "    return x_cat, x_num, y\n",
    "\n",
    "xcat_tr, xnum_tr, y_tr = encode(train_df)\n",
    "xcat_te, xnum_te, y_te = encode(test_df)\n",
    "\n",
    "train_loader = DataLoader(TabDataset(xcat_tr, xnum_tr, y_tr), batch_size=64, shuffle=True)\n",
    "test_loader  = DataLoader(TabDataset(xcat_te, xnum_te, y_te), batch_size=64, shuffle=False)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "deep = SimpleTabTransformer().to(device)\n",
    "\n",
    "opt = torch.optim.AdamW(deep.parameters(), lr=1e-3)\n",
    "loss_fn = nn.SmoothL1Loss()  # Huber\n",
    "\n",
    "# 학습(너무 길면 30~50 epochs 권장)\n",
    "EPOCHS = 50\n",
    "for _ in range(EPOCHS):\n",
    "    deep.train()\n",
    "    for xc, xn, yy in train_loader:\n",
    "        xc, xn, yy = xc.to(device), xn.to(device), yy.to(device)\n",
    "        pred = deep(xc, xn)\n",
    "        loss = loss_fn(pred, yy)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "# 예측\n",
    "deep.eval()\n",
    "preds=[]\n",
    "with torch.no_grad():\n",
    "    for xc, xn, _ in test_loader:\n",
    "        xc, xn = xc.to(device), xn.to(device)\n",
    "        preds.append(deep(xc, xn).cpu().numpy().ravel())\n",
    "deep_pred = np.concatenate(preds)\n",
    "\n",
    "deep_mae = mean_absolute_error(y_test, deep_pred)\n",
    "deep_r2  = r2_score(y_test, deep_pred)\n",
    "\n",
    "# =========================\n",
    "# 4) 수치 출력\n",
    "# =========================\n",
    "print(\"=== 정확도 비교 (일 매출 AMT_sum) ===\")\n",
    "print(f\"RandomForest  MAE={rf_mae:,.0f}  R2={rf_r2:.3f}\")\n",
    "print(f\"DeepLearning  MAE={deep_mae:,.0f}  R2={deep_r2:.3f}\")\n",
    "\n",
    "# =========================\n",
    "# 5) 이미지 1: MAE/R2 막대 그래프\n",
    "# =========================\n",
    "models = [\"RandomForest\", \"DeepLearning\"]\n",
    "mae_vals = [rf_mae, deep_mae]\n",
    "r2_vals  = [rf_r2, deep_r2]\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(models, mae_vals)\n",
    "plt.title(\"MAE Comparison (lower is better)\")\n",
    "plt.ylabel(\"MAE\")\n",
    "plt.savefig(\"accuracy_bar_mae.png\", dpi=200, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(models, r2_vals)\n",
    "plt.title(\"R2 Comparison (higher is better)\")\n",
    "plt.ylabel(\"R2\")\n",
    "plt.savefig(\"accuracy_bar_r2.png\", dpi=200, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "# =========================\n",
    "# 6) 이미지 2: 실제 vs 예측 산점도\n",
    "# =========================\n",
    "plt.figure()\n",
    "plt.scatter(y_test, rf_pred, label=\"RandomForest\")\n",
    "plt.scatter(y_test, deep_pred, label=\"DeepLearning\")\n",
    "plt.title(\"Actual vs Predicted (Test)\")\n",
    "plt.xlabel(\"Actual AMT_sum\")\n",
    "plt.ylabel(\"Predicted AMT_sum\")\n",
    "plt.legend()\n",
    "plt.savefig(\"pred_scatter.png\", dpi=200, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "# =========================\n",
    "# 7) 이미지 3: 오차(Residual) 분포\n",
    "# =========================\n",
    "rf_res = y_test - rf_pred\n",
    "deep_res = y_test - deep_pred\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(rf_res, bins=30, alpha=0.7, label=\"RandomForest\")\n",
    "plt.hist(deep_res, bins=30, alpha=0.7, label=\"DeepLearning\")\n",
    "plt.title(\"Residual Distribution (Test)\")\n",
    "plt.xlabel(\"Residual (Actual - Predicted)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.savefig(\"residual_hist.png\", dpi=200, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "print(\"\\nSaved images:\")\n",
    "print(\"- accuracy_bar_mae.png\")\n",
    "print(\"- accuracy_bar_r2.png\")\n",
    "print(\"- pred_scatter.png\")\n",
    "print(\"- residual_hist.png\")\n",
    "\n",
    "# 해석 가이드 (딱 이것만 보면 됨)\n",
    "# MAE가 낮을수록 좋음 (평균적으로 덜 틀림)\n",
    "# R²가 높을수록 좋음 (패턴 설명력 큼)\n",
    "# pred_scatter.png에서 점들이 대각선(Actual=Pred) 주변에 몰릴수록 좋음\n",
    "# residual_hist.png에서 오차 분포가 0 주변에 좁게 몰릴수록 좋음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e11bbde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 정확도 비교 (일 매출 AMT_sum, Test) ===\n",
      "RF   : MAE=17,858,319  R2=0.724\n",
      "XGB  : MAE=19,616,764  R2=0.671\n",
      "Deep : MAE=175,292,836  R2=-10.804\n",
      "\n",
      "Saved images:\n",
      "- compare_mae.png\n",
      "- compare_r2.png\n",
      "- compare_scatter.png\n",
      "- compare_residual_hist.png\n",
      "- compare_residual_box.png\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# =========================\n",
    "# 1) 데이터 로드 & 일별 집계\n",
    "# =========================\n",
    "CSV_PATH = \"SUWON_S_DATA_TABLE_GENDER_SUM.csv\"\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "df[\"TA_YMD\"] = pd.to_datetime(df[\"TA_YMD\"], format=\"%Y%m%d\")\n",
    "\n",
    "daily = df.groupby(\"TA_YMD\", as_index=False).agg(\n",
    "    AMT_sum=(\"AMT\", \"sum\"),\n",
    "    TEMP_mean=(\"TEMP\", \"mean\"),\n",
    "    RAIN_sum=(\"RAIN\", \"sum\"),\n",
    "    DAY_mode=(\"DAY\", lambda x: int(pd.Series(x).mode()[0])),\n",
    ")\n",
    "daily[\"month\"] = daily[\"TA_YMD\"].dt.month\n",
    "daily = daily.sort_values(\"TA_YMD\").reset_index(drop=True)\n",
    "\n",
    "# ✅ 공정 비교: 시간순 split (과거 80% / 미래 20%)\n",
    "split = int(len(daily) * 0.8)\n",
    "train_df = daily.iloc[:split].copy()\n",
    "test_df  = daily.iloc[split:].copy()\n",
    "\n",
    "X_train = train_df[[\"DAY_mode\", \"TEMP_mean\", \"RAIN_sum\", \"month\"]]\n",
    "y_train = train_df[\"AMT_sum\"].values\n",
    "X_test  = test_df[[\"DAY_mode\", \"TEMP_mean\", \"RAIN_sum\", \"month\"]]\n",
    "y_test  = test_df[\"AMT_sum\"].values\n",
    "\n",
    "# =========================\n",
    "# 2) RandomForest\n",
    "# =========================\n",
    "preprocess = ColumnTransformer([\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), [\"DAY_mode\"]),\n",
    "    (\"num\", \"passthrough\", [\"TEMP_mean\", \"RAIN_sum\", \"month\"]),\n",
    "])\n",
    "\n",
    "rf = Pipeline([\n",
    "    (\"prep\", preprocess),\n",
    "    (\"rf\", RandomForestRegressor(\n",
    "        n_estimators=600,\n",
    "        max_depth=12,\n",
    "        min_samples_leaf=2,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "\n",
    "# =========================\n",
    "# 3) XGBoost\n",
    "# =========================\n",
    "xgb = Pipeline([\n",
    "    (\"prep\", preprocess),\n",
    "    (\"xgb\", XGBRegressor(\n",
    "        n_estimators=800,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective=\"reg:squarederror\",\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_pred = xgb.predict(X_test)\n",
    "\n",
    "# =========================\n",
    "# 4) DeepLearning: TabTransformer-style (PyTorch)\n",
    "# =========================\n",
    "class TabDataset(Dataset):\n",
    "    def __init__(self, x_cat, x_num, y):\n",
    "        self.x_cat = torch.tensor(x_cat, dtype=torch.long)\n",
    "        self.x_num = torch.tensor(x_num, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32).view(-1, 1)\n",
    "    def __len__(self): return len(self.y)\n",
    "    def __getitem__(self, idx): return self.x_cat[idx], self.x_num[idx], self.y[idx]\n",
    "\n",
    "class SimpleTabTransformer(nn.Module):\n",
    "    def __init__(self, emb_dim=16, nhead=4, nlayers=2, ff=128, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.day_emb = nn.Embedding(7, emb_dim)\n",
    "        self.mon_emb = nn.Embedding(12, emb_dim)\n",
    "        enc = nn.TransformerEncoderLayer(\n",
    "            d_model=emb_dim, nhead=nhead, dim_feedforward=ff, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.tr = nn.TransformerEncoder(enc, num_layers=nlayers)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(emb_dim + 2, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "    def forward(self, x_cat, x_num):\n",
    "        tokens = torch.stack([self.day_emb(x_cat[:,0]), self.mon_emb(x_cat[:,1])], dim=1)  # (B,2,emb)\n",
    "        z = self.tr(tokens).mean(dim=1)\n",
    "        return self.mlp(torch.cat([z, x_num], dim=1))\n",
    "\n",
    "def encode_for_deep(df_):\n",
    "    # day: 1~7 -> 0~6 / month: 1~12 -> 0~11\n",
    "    day = (df_[\"DAY_mode\"].astype(int).clip(1,7) - 1).values\n",
    "    mon = (df_[\"month\"].astype(int).clip(1,12) - 1).values\n",
    "    x_cat = np.vstack([day, mon]).T\n",
    "    x_num = df_[[\"TEMP_mean\", \"RAIN_sum\"]].values.astype(np.float32)\n",
    "    y = df_[\"AMT_sum\"].values.astype(np.float32)\n",
    "    return x_cat, x_num, y\n",
    "\n",
    "xcat_tr, xnum_tr, y_tr = encode_for_deep(train_df)\n",
    "xcat_te, xnum_te, y_te = encode_for_deep(test_df)\n",
    "\n",
    "train_loader = DataLoader(TabDataset(xcat_tr, xnum_tr, y_tr), batch_size=64, shuffle=True)\n",
    "test_loader  = DataLoader(TabDataset(xcat_te, xnum_te, y_te), batch_size=64, shuffle=False)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "deep = SimpleTabTransformer().to(device)\n",
    "opt = torch.optim.AdamW(deep.parameters(), lr=1e-3)\n",
    "loss_fn = nn.SmoothL1Loss()\n",
    "\n",
    "EPOCHS = 60\n",
    "for _ in range(EPOCHS):\n",
    "    deep.train()\n",
    "    for xc, xn, yy in train_loader:\n",
    "        xc, xn, yy = xc.to(device), xn.to(device), yy.to(device)\n",
    "        pred = deep(xc, xn)\n",
    "        loss = loss_fn(pred, yy)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "deep.eval()\n",
    "deep_preds = []\n",
    "with torch.no_grad():\n",
    "    for xc, xn, _ in test_loader:\n",
    "        xc, xn = xc.to(device), xn.to(device)\n",
    "        deep_preds.append(deep(xc, xn).cpu().numpy().ravel())\n",
    "deep_pred = np.concatenate(deep_preds)\n",
    "\n",
    "# =========================\n",
    "# 5) 평가 지표 계산\n",
    "# =========================\n",
    "def metrics(y_true, y_pred):\n",
    "    return mean_absolute_error(y_true, y_pred), r2_score(y_true, y_pred)\n",
    "\n",
    "rf_mae, rf_r2 = metrics(y_test, rf_pred)\n",
    "xgb_mae, xgb_r2 = metrics(y_test, xgb_pred)\n",
    "deep_mae, deep_r2 = metrics(y_test, deep_pred)\n",
    "\n",
    "print(\"=== 정확도 비교 (일 매출 AMT_sum, Test) ===\")\n",
    "print(f\"RF   : MAE={rf_mae:,.0f}  R2={rf_r2:.3f}\")\n",
    "print(f\"XGB  : MAE={xgb_mae:,.0f}  R2={xgb_r2:.3f}\")\n",
    "print(f\"Deep : MAE={deep_mae:,.0f}  R2={deep_r2:.3f}\")\n",
    "\n",
    "# =========================\n",
    "# 6) 그래프 저장 (matplotlib, 색상 미지정)\n",
    "# =========================\n",
    "models = [\"RF\", \"XGB\", \"Deep\"]\n",
    "maes = [rf_mae, xgb_mae, deep_mae]\n",
    "r2s  = [rf_r2, xgb_r2, deep_r2]\n",
    "\n",
    "# (1) MAE bar\n",
    "plt.figure()\n",
    "plt.bar(models, maes)\n",
    "plt.title(\"MAE Comparison (lower is better)\")\n",
    "plt.ylabel(\"MAE\")\n",
    "plt.savefig(\"compare_mae.png\", dpi=200, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "# (2) R2 bar\n",
    "plt.figure()\n",
    "plt.bar(models, r2s)\n",
    "plt.title(\"R2 Comparison (higher is better)\")\n",
    "plt.ylabel(\"R2\")\n",
    "plt.savefig(\"compare_r2.png\", dpi=200, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "# (3) Scatter: Actual vs Pred\n",
    "plt.figure()\n",
    "plt.scatter(y_test, rf_pred, label=\"RF\")\n",
    "plt.scatter(y_test, xgb_pred, label=\"XGB\")\n",
    "plt.scatter(y_test, deep_pred, label=\"Deep\")\n",
    "plt.title(\"Actual vs Predicted (Test)\")\n",
    "plt.xlabel(\"Actual AMT_sum\")\n",
    "plt.ylabel(\"Predicted AMT_sum\")\n",
    "plt.legend()\n",
    "plt.savefig(\"compare_scatter.png\", dpi=200, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "# (4) Residual hist\n",
    "rf_res = y_test - rf_pred\n",
    "xgb_res = y_test - xgb_pred\n",
    "deep_res = y_test - deep_pred\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(rf_res, bins=30, alpha=0.7, label=\"RF\")\n",
    "plt.hist(xgb_res, bins=30, alpha=0.7, label=\"XGB\")\n",
    "plt.hist(deep_res, bins=30, alpha=0.7, label=\"Deep\")\n",
    "plt.title(\"Residual Distribution (Test)\")\n",
    "plt.xlabel(\"Residual (Actual - Predicted)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.savefig(\"compare_residual_hist.png\", dpi=200, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "# (5) Residual boxplot\n",
    "plt.figure()\n",
    "plt.boxplot([rf_res, xgb_res, deep_res], labels=models)\n",
    "plt.title(\"Residual Boxplot (Test)\")\n",
    "plt.ylabel(\"Residual (Actual - Predicted)\")\n",
    "plt.savefig(\"compare_residual_box.png\", dpi=200, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "print(\"\\nSaved images:\")\n",
    "print(\"- compare_mae.png\")\n",
    "print(\"- compare_r2.png\")\n",
    "print(\"- compare_scatter.png\")\n",
    "print(\"- compare_residual_hist.png\")\n",
    "print(\"- compare_residual_box.png\")\n",
    "\n",
    "# 결과를 어떻게 보면 좋나\n",
    "# compare_r2.png에서 R²가 가장 높은 모델이 “패턴 설명력” 최고\n",
    "# compare_mae.png에서 MAE가 가장 낮은 모델이 “평균 오차” 최소\n",
    "# compare_residual_box.png에서 박스가 좁고 0에 가까울수록 안정적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e26e5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved: hourly_metrics.csv\n",
      "    HOUR Model           MAE         R2\n",
      "0      1  Deep  5.432525e+06  -1.935687\n",
      "1      1    RF  1.905321e+06   0.543460\n",
      "2      1   XGB  2.047588e+06   0.470522\n",
      "3      2  Deep  4.389300e+06 -11.552707\n",
      "4      2    RF  1.158008e+06  -0.306459\n",
      "5      2   XGB  1.242515e+06  -0.474685\n",
      "6      3  Deep  1.087496e+07  -8.907372\n",
      "7      3    RF  1.777713e+06  -0.079037\n",
      "8      3   XGB  1.986194e+06  -0.112701\n",
      "9      4  Deep  2.540037e+07 -46.107940\n",
      "10     4    RF  2.963726e+06  -0.068408\n",
      "11     4   XGB  3.257487e+06  -0.293305\n",
      "\n",
      "Saved images:\n",
      "- hourly_mae_heatmap.png\n",
      "- hourly_r2_heatmap.png\n",
      "- hourly_mae_lines.png\n",
      "- hourly_r2_lines.png\n",
      "- hourly_best_model_mae.png\n",
      "- hourly_best_model_r2.png\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# =========================\n",
    "# 0) 설정\n",
    "# =========================\n",
    "CSV_PATH = \"SUWON_S_DATA_TABLE_GENDER_SUM.csv\"\n",
    "MIN_DAYS_PER_HOUR = 120      # 시간대별 일수 너무 적으면 스킵\n",
    "TRAIN_RATIO = 0.8\n",
    "DEEP_EPOCHS = 40             # GPU 있으면 60~100 추천\n",
    "DEEP_BATCH = 64\n",
    "SEED = 42\n",
    "\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# =========================\n",
    "# 1) 시간대별(HOUR) 일매출 데이터셋 생성\n",
    "#    - 타겟: 해당 시간대의 일매출 AMT_sum\n",
    "#    - 피처: DAY(요일), month, TEMP_mean, RAIN_sum\n",
    "# =========================\n",
    "def build_hourly_daily(df: pd.DataFrame, hour: int) -> pd.DataFrame:\n",
    "    sub = df[df[\"HOUR\"] == hour].copy()\n",
    "    sub[\"TA_YMD\"] = pd.to_datetime(sub[\"TA_YMD\"], format=\"%Y%m%d\")\n",
    "\n",
    "    daily = sub.groupby(\"TA_YMD\", as_index=False).agg(\n",
    "        AMT_sum=(\"AMT\", \"sum\"),\n",
    "        TEMP_mean=(\"TEMP\", \"mean\"),\n",
    "        RAIN_sum=(\"RAIN\", \"sum\"),\n",
    "        DAY_mode=(\"DAY\", lambda x: int(pd.Series(x).mode()[0])),\n",
    "    )\n",
    "    daily[\"month\"] = daily[\"TA_YMD\"].dt.month\n",
    "    return daily.sort_values(\"TA_YMD\").reset_index(drop=True)\n",
    "\n",
    "def time_split(df: pd.DataFrame, train_ratio=0.8):\n",
    "    n = len(df)\n",
    "    split = int(n * train_ratio)\n",
    "    return df.iloc[:split].copy(), df.iloc[split:].copy()\n",
    "\n",
    "# =========================\n",
    "# 2) 공통 전처리 (RF/XGB)\n",
    "# =========================\n",
    "def make_preprocessor():\n",
    "    return ColumnTransformer([\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), [\"DAY_mode\"]),\n",
    "        (\"num\", \"passthrough\", [\"TEMP_mean\", \"RAIN_sum\", \"month\"]),\n",
    "    ])\n",
    "\n",
    "# =========================\n",
    "# 3) 딥러닝 모델 (TabTransformer-style)\n",
    "# =========================\n",
    "class TabDataset(Dataset):\n",
    "    def __init__(self, x_cat, x_num, y):\n",
    "        self.x_cat = torch.tensor(x_cat, dtype=torch.long)\n",
    "        self.x_num = torch.tensor(x_num, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32).view(-1, 1)\n",
    "    def __len__(self): return len(self.y)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x_cat[idx], self.x_num[idx], self.y[idx]\n",
    "\n",
    "class SimpleTabTransformer(nn.Module):\n",
    "    def __init__(self, emb_dim=16, nhead=4, nlayers=2, ff=128, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.day_emb = nn.Embedding(7, emb_dim)\n",
    "        self.mon_emb = nn.Embedding(12, emb_dim)\n",
    "        enc = nn.TransformerEncoderLayer(\n",
    "            d_model=emb_dim, nhead=nhead, dim_feedforward=ff, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.tr = nn.TransformerEncoder(enc, num_layers=nlayers)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(emb_dim + 2, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "    def forward(self, x_cat, x_num):\n",
    "        tokens = torch.stack([self.day_emb(x_cat[:,0]), self.mon_emb(x_cat[:,1])], dim=1)\n",
    "        z = self.tr(tokens).mean(dim=1)\n",
    "        return self.mlp(torch.cat([z, x_num], dim=1))\n",
    "\n",
    "def encode_for_deep(df_):\n",
    "    # day: 1~7 -> 0~6 / month: 1~12 -> 0~11\n",
    "    day = (df_[\"DAY_mode\"].astype(int).clip(1,7) - 1).values\n",
    "    mon = (df_[\"month\"].astype(int).clip(1,12) - 1).values\n",
    "    x_cat = np.vstack([day, mon]).T\n",
    "    x_num = df_[[\"TEMP_mean\", \"RAIN_sum\"]].values.astype(np.float32)\n",
    "    y = df_[\"AMT_sum\"].values.astype(np.float32)\n",
    "    return x_cat, x_num, y\n",
    "\n",
    "def train_predict_deep(train_df, test_df, epochs=40, batch=64):\n",
    "    xcat_tr, xnum_tr, y_tr = encode_for_deep(train_df)\n",
    "    xcat_te, xnum_te, y_te = encode_for_deep(test_df)\n",
    "\n",
    "    tr_loader = DataLoader(TabDataset(xcat_tr, xnum_tr, y_tr), batch_size=batch, shuffle=True)\n",
    "    te_loader = DataLoader(TabDataset(xcat_te, xnum_te, y_te), batch_size=batch, shuffle=False)\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = SimpleTabTransformer().to(device)\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "    loss_fn = nn.SmoothL1Loss()\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        model.train()\n",
    "        for xc, xn, yy in tr_loader:\n",
    "            xc, xn, yy = xc.to(device), xn.to(device), yy.to(device)\n",
    "            pred = model(xc, xn)\n",
    "            loss = loss_fn(pred, yy)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "    model.eval()\n",
    "    preds=[]\n",
    "    with torch.no_grad():\n",
    "        for xc, xn, _ in te_loader:\n",
    "            xc, xn = xc.to(device), xn.to(device)\n",
    "            preds.append(model(xc, xn).cpu().numpy().ravel())\n",
    "    return np.concatenate(preds)\n",
    "\n",
    "# =========================\n",
    "# 4) HOUR별 학습/평가 루프\n",
    "# =========================\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "hours = sorted(df[\"HOUR\"].unique())\n",
    "rows = []\n",
    "\n",
    "for h in hours:\n",
    "    daily_h = build_hourly_daily(df, int(h))\n",
    "    if len(daily_h) < MIN_DAYS_PER_HOUR:\n",
    "        print(f\"[skip] HOUR={h} days={len(daily_h)} (<{MIN_DAYS_PER_HOUR})\")\n",
    "        continue\n",
    "\n",
    "    train_h, test_h = time_split(daily_h, TRAIN_RATIO)\n",
    "    y_test = test_h[\"AMT_sum\"].values\n",
    "\n",
    "    X_train = train_h[[\"DAY_mode\",\"TEMP_mean\",\"RAIN_sum\",\"month\"]]\n",
    "    y_train = train_h[\"AMT_sum\"].values\n",
    "    X_test  = test_h[[\"DAY_mode\",\"TEMP_mean\",\"RAIN_sum\",\"month\"]]\n",
    "\n",
    "    pre = make_preprocessor()\n",
    "\n",
    "    # RF\n",
    "    rf = Pipeline([\n",
    "        (\"prep\", pre),\n",
    "        (\"rf\", RandomForestRegressor(\n",
    "            n_estimators=500, max_depth=12, min_samples_leaf=2,\n",
    "            random_state=SEED, n_jobs=-1\n",
    "        ))\n",
    "    ])\n",
    "    rf.fit(X_train, y_train)\n",
    "    rf_pred = rf.predict(X_test)\n",
    "\n",
    "    # XGB\n",
    "    xgb = Pipeline([\n",
    "        (\"prep\", pre),\n",
    "        (\"xgb\", XGBRegressor(\n",
    "            n_estimators=800, max_depth=6, learning_rate=0.05,\n",
    "            subsample=0.8, colsample_bytree=0.8,\n",
    "            objective=\"reg:squarederror\",\n",
    "            random_state=SEED\n",
    "        ))\n",
    "    ])\n",
    "    xgb.fit(X_train, y_train)\n",
    "    xgb_pred = xgb.predict(X_test)\n",
    "\n",
    "    # Deep\n",
    "    deep_pred = train_predict_deep(train_h, test_h, epochs=DEEP_EPOCHS, batch=DEEP_BATCH)\n",
    "\n",
    "    # Metrics\n",
    "    for model_name, pred in [(\"RF\", rf_pred), (\"XGB\", xgb_pred), (\"Deep\", deep_pred)]:\n",
    "        rows.append({\n",
    "            \"HOUR\": int(h),\n",
    "            \"Model\": model_name,\n",
    "            \"MAE\": float(mean_absolute_error(y_test, pred)),\n",
    "            \"R2\": float(r2_score(y_test, pred)),\n",
    "        })\n",
    "\n",
    "result = pd.DataFrame(rows).sort_values([\"HOUR\",\"Model\"]).reset_index(drop=True)\n",
    "result.to_csv(\"hourly_metrics.csv\", index=False)\n",
    "print(\"\\nSaved: hourly_metrics.csv\")\n",
    "print(result.head(12))\n",
    "\n",
    "# =========================\n",
    "# 5) 그래프 생성\n",
    "# =========================\n",
    "# 피벗 (HOUR x Model)\n",
    "mae_pivot = result.pivot(index=\"HOUR\", columns=\"Model\", values=\"MAE\").sort_index()\n",
    "r2_pivot  = result.pivot(index=\"HOUR\", columns=\"Model\", values=\"R2\").sort_index()\n",
    "\n",
    "# --- (1) MAE heatmap (imshow)\n",
    "plt.figure()\n",
    "plt.imshow(mae_pivot.values, aspect=\"auto\")\n",
    "plt.title(\"MAE Heatmap (HOUR x Model)  - lower is better\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"HOUR\")\n",
    "plt.xticks(range(len(mae_pivot.columns)), mae_pivot.columns)\n",
    "plt.yticks(range(len(mae_pivot.index)), mae_pivot.index)\n",
    "plt.colorbar(label=\"MAE\")\n",
    "plt.savefig(\"hourly_mae_heatmap.png\", dpi=200, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "# --- (2) R2 heatmap\n",
    "plt.figure()\n",
    "plt.imshow(r2_pivot.values, aspect=\"auto\")\n",
    "plt.title(\"R2 Heatmap (HOUR x Model)  - higher is better\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"HOUR\")\n",
    "plt.xticks(range(len(r2_pivot.columns)), r2_pivot.columns)\n",
    "plt.yticks(range(len(r2_pivot.index)), r2_pivot.index)\n",
    "plt.colorbar(label=\"R2\")\n",
    "plt.savefig(\"hourly_r2_heatmap.png\", dpi=200, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "# --- (3) MAE lines\n",
    "plt.figure()\n",
    "for m in mae_pivot.columns:\n",
    "    plt.plot(mae_pivot.index, mae_pivot[m].values, marker=\"o\", label=m)\n",
    "plt.title(\"MAE by HOUR (lower is better)\")\n",
    "plt.xlabel(\"HOUR\")\n",
    "plt.ylabel(\"MAE\")\n",
    "plt.legend()\n",
    "plt.savefig(\"hourly_mae_lines.png\", dpi=200, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "# --- (4) R2 lines\n",
    "plt.figure()\n",
    "for m in r2_pivot.columns:\n",
    "    plt.plot(r2_pivot.index, r2_pivot[m].values, marker=\"o\", label=m)\n",
    "plt.title(\"R2 by HOUR (higher is better)\")\n",
    "plt.xlabel(\"HOUR\")\n",
    "plt.ylabel(\"R2\")\n",
    "plt.legend()\n",
    "plt.savefig(\"hourly_r2_lines.png\", dpi=200, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "# --- (5) Best model per hour (MAE)\n",
    "best_mae = mae_pivot.idxmin(axis=1)\n",
    "plt.figure()\n",
    "plt.bar(best_mae.index.astype(str), best_mae.index*0 + 1)  # 막대 높이는 의미 없음(라벨용)\n",
    "plt.title(\"Best Model by HOUR (based on MAE)\")\n",
    "plt.xlabel(\"HOUR\")\n",
    "plt.ylabel(\"Best (MAE)\")\n",
    "# 막대 위에 모델명 표시\n",
    "for i, (h, bm) in enumerate(best_mae.items()):\n",
    "    plt.text(i, 1.02, bm, ha=\"center\", va=\"bottom\")\n",
    "plt.ylim(0, 1.2)\n",
    "plt.savefig(\"hourly_best_model_mae.png\", dpi=200, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "# --- (6) Best model per hour (R2)\n",
    "best_r2 = r2_pivot.idxmax(axis=1)\n",
    "plt.figure()\n",
    "plt.bar(best_r2.index.astype(str), best_r2.index*0 + 1)\n",
    "plt.title(\"Best Model by HOUR (based on R2)\")\n",
    "plt.xlabel(\"HOUR\")\n",
    "plt.ylabel(\"Best (R2)\")\n",
    "for i, (h, bm) in enumerate(best_r2.items()):\n",
    "    plt.text(i, 1.02, bm, ha=\"center\", va=\"bottom\")\n",
    "plt.ylim(0, 1.2)\n",
    "plt.savefig(\"hourly_best_model_r2.png\", dpi=200, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "print(\"\\nSaved images:\")\n",
    "print(\"- hourly_mae_heatmap.png\")\n",
    "print(\"- hourly_r2_heatmap.png\")\n",
    "print(\"- hourly_mae_lines.png\")\n",
    "print(\"- hourly_r2_lines.png\")\n",
    "print(\"- hourly_best_model_mae.png\")\n",
    "print(\"- hourly_best_model_r2.png\")\n",
    "\n",
    "# hourly_r2_lines.png : 시간대별로 어떤 모델이 강한지 한눈에 보임\n",
    "# hourly_mae_heatmap.png : 특정 시간대에서 튀는 구간(예측 어려운 시간대) 식별\n",
    "# hourly_best_model_mae.png / hourly_best_model_r2.png : 시간대별 운영 모델 선택에 바로 사용 가능"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-dl-nlp(ipykernel)",
   "language": "python",
   "name": "ml-dl-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
