{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c62a89c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "div.container{width:90% !important;}\n",
       "div.cell.code_cell.rendered{width:100%;}\n",
       "div.input_prompt{padding:0px;}\n",
       "div.CodeMirror {font-family:Consolas; font-size:12pt;}\n",
       "div.text_cell_render.rendered_html{font-size:12pt;}\n",
       "div.output {font-size:12pt; font-weight:bold;}\n",
       "div.input {font-family:Consolas; font-size:12pt;}\n",
       "div.prompt {min-width:70px;}\n",
       "div#toc-wrapper{padding-top:120px;}\n",
       "div.text_cell_render ul li{font-size:12pt;padding:5px;}\n",
       "table.dataframe{font-size:12px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    "div.container{width:90% !important;}\n",
    "div.cell.code_cell.rendered{width:100%;}\n",
    "div.input_prompt{padding:0px;}\n",
    "div.CodeMirror {font-family:Consolas; font-size:12pt;}\n",
    "div.text_cell_render.rendered_html{font-size:12pt;}\n",
    "div.output {font-size:12pt; font-weight:bold;}\n",
    "div.input {font-family:Consolas; font-size:12pt;}\n",
    "div.prompt {min-width:70px;}\n",
    "div#toc-wrapper{padding-top:120px;}\n",
    "div.text_cell_render ul li{font-size:12pt;padding:5px;}\n",
    "table.dataframe{font-size:12px;}\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ab8289",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">ch2.Ollama_LLM활용의기본개념(LangChain)</span>\n",
    "# 1. LLM을 활용하여 답변 생성하기\n",
    "## 1) Ollama를 이용한 로컬 LLM 이용\n",
    " - 성능은 GPT, CLaude 같은 모델보다 떨어지나, 개념설명을 위해 open source 모델 사용\n",
    " - ollama.com 다운로드 -> 설치 -> 모델 pull\n",
    "     - cmd창이나 powershell 창에 ollama pull deepseek-r1:1.5b https://docs.langchain.com/oss/python/integrations/chat/ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc0de2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "llm = ChatOllama(model=\"deepseek-r1:1.5b\")\n",
    "result = llm.invoke(\"What is the captital of Korea?\")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4096d3ce",
   "metadata": {},
   "source": [
    "## 모델 pull\n",
    " - cmd창이나 powershell창(window키+R에서 powershell)에서 ollama pull llama3.2:1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675051ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "llm = ChatOllama(model=\"llama3.2:1b\")\n",
    "result = llm.invoke(\"What is the capital of Korea?\")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba83028",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffa13b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm.invoke(\"일본 수도가 어디예요?\")\n",
    "result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e851cd",
   "metadata": {},
   "source": [
    "## 2) openai 활용\n",
    " - pip install langchain-openai\n",
    " - https://auth.openai.com/log-in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7083e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 환경변수 가져오기\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "#os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad2cc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-5-nano\")\n",
    "result = llm.invoke(\"What is the capitaal of Korea? Return the name of the city only.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75388cea",
   "metadata": {},
   "source": [
    "# 2. 렝체인 스타일로 프롬프트 작성\n",
    " - 프롬프트 : llm호출시 쓰는 질문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52f9c097",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "llm = ChatOllama(model=\"llama3.2:1b\")\n",
    "# llm.invoke(0)\n",
    "# PromptValue, str, BaseMessages리스트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd370ae5",
   "metadata": {},
   "source": [
    "## 1) 기본 프롬프트 템플릿 사용\n",
    " - PromptTemplate을 사용하여 변수가 포함된 템플릿을 작성하면 PromptValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "856965f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text='What is the capital of Korea?'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"The capital of South Korea is Seoul. However, it's worth noting that North Korea also claims Pyongyang as its capital.\", additional_kwargs={}, response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-12-09T06:07:58.0160114Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2649207100, 'load_duration': 1606706900, 'prompt_eval_count': 32, 'prompt_eval_duration': 191722900, 'eval_count': 25, 'eval_duration': 700020600, 'logprobs': None, 'model_name': 'llama3.2:1b', 'model_provider': 'ollama'}, id='lc_run--019b01b9-3be5-7161-9dee-106c804d9995-0', usage_metadata={'input_tokens': 32, 'output_tokens': 25, 'total_tokens': 57})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "llm = ChatOllama(model=\"llama3.2:1b\")\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"What is the capital of {country}?\", # {}안의 값을 새로운 값으로 대입 가능\n",
    "    input_variables = [\"country\"]\n",
    ")\n",
    "# country = input('어느 나라의 수도를 알고 싶으신가요?')\n",
    "prompt = prompt_template.invoke({\"country\":\"Korea\"})\n",
    "print(prompt)\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d7c008",
   "metadata": {},
   "source": [
    "## 2) 메세지 기반 프롬프트 작성\n",
    " - BaseMessage 리스트\n",
    " - BaseMessage 상속받은 클래스 : AIMessage, HumanMessage, SystemMessage, ToolMessage\n",
    " - vscode에서 ctrl+shift+p : python:select interpreter입력 -> python환경선택\n",
    " - vscode에서 커널 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1206fed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I think there may be a small mistake here. The capital of South Korea is Seoul, and the capital of North Korea is Pyongyang.\\n\\nIt's possible you're thinking of Japan, whose capital is Tokyo. Would you like more information about either Japan or Korea?\", additional_kwargs={}, response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-12-09T06:08:45.142407Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2440738200, 'load_duration': 96016700, 'prompt_eval_count': 86, 'prompt_eval_duration': 433491200, 'eval_count': 53, 'eval_duration': 1657664300, 'logprobs': None, 'model_name': 'llama3.2:1b', 'model_provider': 'ollama'}, id='lc_run--019b01b9-f4cc-78c1-8aac-603adbc6361d-0', usage_metadata={'input_tokens': 86, 'output_tokens': 53, 'total_tokens': 139})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "message_list = [\n",
    "    SystemMessage(content=\"You are a helpful assistant!\"), # 페르소나 부여\n",
    "    HumanMessage(content=\"What is the capital of Italy?\"), # 모범질문\n",
    "    AIMessage(content=\"The capital of Italy is Rome.\"),    # 모범답안\n",
    "    HumanMessage(content=\"What is the capital of France?\"), # 모범질문\n",
    "    AIMessage(content=\"The capital of France is Paris.\"),    # 모범답안\n",
    "    HumanMessage(content=\"What is the capital of Korea?\")\n",
    "]\n",
    "llm.invoke(message_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31a886a",
   "metadata": {},
   "source": [
    "## 3) ChatPromptTemplate 사용\n",
    " - BaseMessage리스트 -> 튜플리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65d6d09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어느 나라 수도가 궁금하세요일본\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The capital of Japan is Tokyo.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 위의 BaseMessage 리스트를 수정\n",
    "# PromptTemplate : 프롬프트에 변수포함, \n",
    "# ChatPromptTemplate : SystemPrompt설정(페르소나), few shot설정, 변수포함\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "chatPrompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpfull assistant!\"),\n",
    "    ('human', \"What is the capital of Italy?\"), # 모범질문\n",
    "    (\"ai\", \"The capital of Italy is Rome.\"),    # 모범답안\n",
    "    ('human', \"What is the capital of France?\"), # 모범질문\n",
    "    (\"ai\", \"The capital of France is Paris.\"),    # 모범답안\n",
    "    (\"human\", \"What is the capital of {country}?\")\n",
    "])\n",
    "country = input(\"어느 나라 수도가 궁금하세요\")\n",
    "prompt = chatPrompt_template.invoke({\"country\": country})\n",
    "#print(\"프롬프트 : \", prompt, type(prompt))\n",
    "result = llm.invoke(prompt)\n",
    "result.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "404d7000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어느 나라 수도가 궁금하세요한국\n",
      "한국의 수도는 Seoul입니다. 그것은 한국 전역에서 가장 큰 도시이며, 그 때에 이웃된 다른 도시를 상당히 outnumber했습니다.\n"
     ]
    }
   ],
   "source": [
    "chatPromptTemplate = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 대한민국 정보 전문 도우미입니다\"),\n",
    "    (\"human\", \"{country}의 수도가 어디예요!\")\n",
    "])\n",
    "country = input(\"어느 나라 수도가 궁금하세요\")\n",
    "prompt = chatPromptTemplate.invoke({\"country\":country})\n",
    "# print(prompt)\n",
    "result = llm.invoke(prompt)\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec8974e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='한국의 수도는 Seoul입니다. 그것은 한국 전역에서 가장 큰 도시이며, 그 때에 이웃된 다른 도시를 상당히 outnumber했습니다.', additional_kwargs={}, response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-12-09T06:41:27.0456109Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1492017800, 'load_duration': 134154300, 'prompt_eval_count': 43, 'prompt_eval_duration': 199166300, 'eval_count': 34, 'eval_duration': 953342600, 'logprobs': None, 'model_name': 'llama3.2:1b', 'model_provider': 'ollama'}, id='lc_run--019b01d7-e82f-7e00-9c2d-aef0e4b0d6bb-0', usage_metadata={'input_tokens': 43, 'output_tokens': 34, 'total_tokens': 77})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5952ca5b",
   "metadata": {},
   "source": [
    "# 3. 답변 형식 컨트롤 하기\n",
    " - llm.invoke()의 결과는 AIMessage() -> string이나 json, 객체 : OutputParser이용\n",
    " ## 1) 문자열 출력 파서 이용\n",
    "  - StrOutputParser를 사용하여 LLM출력(AIMessage)을 단순 문자열로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a272a3b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seoul'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "# 명시적인 지시하상이 포함된 프롬프트\n",
    "prompt_template = PromptTemplate(\n",
    "    template = \"What is the capital of {country}. Retrun the name of the city only.\",\n",
    "    input_variables = [\"country\"]\n",
    ")\n",
    "# 프롬프트 템플릿에 값 주입\n",
    "prompt = prompt_template.invoke({\"country\": \"Korea\"})\n",
    "# print(prompt)\n",
    "ai_message = llm.invoke(prompt)\n",
    "# print(ai_message)\n",
    "# 문자열 출력 파서를 이요하여 llm응답(AIMessage객체)을 단순 문자열로 변환\n",
    "output_parser = StrOutputParser()\n",
    "result = output_parser.invoke(ai_message)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2c79a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seoul'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parser.invoke(llm.invoke(prompt_template.invoke({\"country\":\"Korea\"})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8d9ed1a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of South Korea is Seoul, and the administrative division that includes Pyongyang in North Korea is known as Kaesong Pukguksa ( Province of Kaesong)'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 변수설정, system, few shot 지정\n",
    "chat_prompt_template = ChatPromptTemplate([\n",
    "    (\"system\", \"You are a helpful assistant with expertise in South Korea.\"),\n",
    "    ('human', \"What is the capital of Italy?\"), # 모범질문\n",
    "    (\"ai\", \"Rome.\"),    # 모범답안\n",
    "    ('human', \"What is the capital of France?\"), # 모범질문\n",
    "    (\"ai\", \"Paris.\"),    # 모범답안\n",
    "    (\"human\", \"What is the capital of {country}?\")#Return the name of the city only\n",
    "])\n",
    "output_parser = StrOutputParser()\n",
    "output_parser.invoke(llm.invoke(chat_prompt_template.invoke({\"country\":\"Korea\"})))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe03f0a3",
   "metadata": {},
   "source": [
    "## 2) Json 출력 파서 이용\n",
    " - {'name':'홍길동', 'age':22}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2cbf2d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'capital': 'Seoul', 'population': 51.8, 'language': 'Korean', 'currency': 'Korean won'} <class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "country_detail_prompt = PromptTemplate(\n",
    "    template = \"\"\"Give following information about {country}.\n",
    "    - Capital\n",
    "    - Population\n",
    "    - Language\n",
    "    - Currency\n",
    "    Return in JSON format and return the JSON dictionary only\"\"\",\n",
    "    input_variables=[\"country\"]\n",
    ")\n",
    "prompt = country_detail_prompt.invoke({\"country\":\"Korea\"})\n",
    "ai_message = llm.invoke(prompt)\n",
    "# print(ai_message.content)\n",
    "output_parser = JsonOutputParser()\n",
    "json_result = output_parser.invoke(ai_message)\n",
    "print(json_result, type(json_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0e56251f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'capital': 'Tokyo',\n",
       " 'population': '127,112,533',\n",
       " 'language': 'Japanese',\n",
       " 'currency': 'Japan yen'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parser.invoke(llm.invoke(country_detail_prompt.invoke({\"country\":\"Japen\"})))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8702311",
   "metadata": {},
   "source": [
    "## 3) 구조화된 출력 사용\n",
    " - Pydantic 모델을 사용하여 LLM출력을 구조화된 형식으로 받기(JsonParser보다 훨씬 안정적)\n",
    " - Pydantic : 데이터유효성검사, 설정관리를 간편하게 해주는 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8aed3b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.User object at 0x0000023F33DED150>\n"
     ]
    }
   ],
   "source": [
    "class User:\n",
    "    def __init__(self, id, name, is_active=True):\n",
    "        self.id   = id\n",
    "        self.name = name\n",
    "        self.is_active = is_active\n",
    "user = User(\"1\", \"홍길동\", False)\n",
    "print(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eb130966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id=1 name='홍길동' is_active=True\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "class User(BaseModel):\n",
    "    # gt=0:id>0 / ge=0:id>=0 / lt=0:id<0 / le=0:id<=0\n",
    "    id:int   = Field(gt=0,         description=\"id\")\n",
    "    name:str = Field(min_length=2, description=\"name\")\n",
    "    is_active:bool = Field(default=True, description=\"id활성화 여부\")\n",
    "user = User(id=\"1\", name=\"홍길동\")\n",
    "print(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dd96641c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountryDetail(capital='Seoul', population=51, language='Korean', currency='Korean won')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_detail_prompt = PromptTemplate(\n",
    "    template = \"\"\"Give following information about {country}.\n",
    "    - Capital\n",
    "    - Population\n",
    "    - Language\n",
    "    - Currency\n",
    "    Return in JSON format and return the JSON dictionary only\"\"\",\n",
    "    input_variables=[\"country\"]\n",
    ")\n",
    "class CountryDetail(BaseModel): #description: 더 정확한 출력 유도\n",
    "    capital:str  = Field(description=\"the capital of the country\")\n",
    "    population:int = Field(description=\"the population of the country\")\n",
    "    language:str = Field(description=\"the language of the country\")\n",
    "    currency:str = Field(description=\"the currency of the country\")\n",
    "# 출력 형식 파서 + LLM\n",
    "structedllm = llm.with_structured_output(CountryDetail)\n",
    "# llm.invoke(country_detail_prompt.invoke({\"country\":\"Korea\"}))\n",
    "info = structedllm.invoke(country_detail_prompt.invoke({\"country\":\"Korea\"}))\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e906e53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.CountryDetail"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7a35e078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Seoul', 51, 'Korean', 'Korean won')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info.capital, info.population, info.language, info.currency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cd676f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info를 json 스타일로 : {\"capital\":\"Seoul\",\"population\":51,\"language\":\"Korean\",\"currency\":\"Korean won\"}\n",
      "info를 dict로 : {'capital': 'Seoul', 'population': 51, 'language': 'Korean', 'currency': 'Korean won'}\n",
      "info를 dict로 : {'capital': 'Seoul', 'population': 51, 'language': 'Korean', 'currency': 'Korean won'}\n"
     ]
    }
   ],
   "source": [
    "print(\"info를 json 스타일로 :\", info.model_dump_json())\n",
    "print(\"info를 dict로 :\", info.model_dump())\n",
    "print(\"info를 dict로 :\", info.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c9ada3d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(info.model_dump_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b50a7fb",
   "metadata": {},
   "source": [
    "# 4. LCEL을 활용한 LangChain 생성하기\n",
    "## 1) 문자열 출력 파서 이용\n",
    " - invoke\n",
    " - StrOutputParser, ChatOllama, PromptTemplate등은 모두 Runnable로부터 상속 받음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c4555a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seoul'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.2:1b\",\n",
    "                temperature=0) # 일관된 답변(보수적인 답변)\n",
    "prompt_template = PromptTemplate(\n",
    "    template = \"What is the capital of {country}. Retrun the name of the city only.\",\n",
    "    input_variables = [\"country\"]\n",
    ")\n",
    "output_parser = StrOutputParser() # AIMessage()를 Str변환\n",
    "output_parser.invoke(llm.invoke(prompt_template.invoke({\"country\":\"Korea\"})))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de47ec40",
   "metadata": {},
   "source": [
    "## 2) LCEL을 사용한 간단한 체인 구성\n",
    " - 파이프연산자(|) 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "65c3d93d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seoul'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 프롬프트 템플릿 -> llm -> 출력파서를 연결하는 체인 생성\n",
    "capital_chain = prompt_template | llm | output_parser\n",
    "# 생성된 체인 invoke\n",
    "capital_chain.invoke({\"country\":\"Korea\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2076054b",
   "metadata": {},
   "source": [
    "## 3) 복합체인 구성\n",
    " - 여러 단계의 추론이 필요한 경우(체인 연결)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c6bd86a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Italy'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 나라 설명 -> 나라이름\n",
    "country_prompt = PromptTemplate(\n",
    "    template=\"\"\"Guess the name of the country based on the following informat:\n",
    "    {information}\n",
    "    Return the name of the country only\"\"\",\n",
    "    input_variables=[\"information\"]\n",
    ")\n",
    "output_parser.invoke(llm.invoke(country_prompt.invoke({\"information\":\n",
    "                            \"This country is very famous for its wine\"})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6784a380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Italy'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 나라명 추출 체인 생성\n",
    "country_chain = country_prompt | llm | output_parser\n",
    "country_chain.invoke({\"information\":\"This country is very famous for its wine\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0f4210b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rome'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 복합체인 : 나라설명 -> 나라명(country_chain)\n",
    "#                        나라명 -> 수도(capital_chain)\n",
    "final_chain = country_chain | capital_chain\n",
    "final_chain.invoke({\"information\":\"This country is very famous for its wine\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a72dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 복합체인 : information -> country_chain -> (나라명을 country) -> capital_chain\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "final_chain = {\"information\":RunnablePassthrough()} | \\\n",
    "                {\"country\":country_chain} | capital_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be189c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chain.invoke(\"This country is very famous for its wine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730d2d1c",
   "metadata": {},
   "source": [
    " - 한글 지원이 안 되는 모델은 렝체인 연결이 잘 안 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8a1d8ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 나라 설명 -> 나라이름\n",
    "country_prompt = PromptTemplate(\n",
    "    template=\"\"\"다음의 {information} 설명을 보고 나라이름을 맞춰봐:\n",
    "    {information}\n",
    "    나라 이름만 한국어로 reutrn 해 줘\"\"\",\n",
    "    input_variables=[\"information\"]\n",
    ")\n",
    "output_parser.invoke(llm.invoke(country_prompt.invoke({\"information\":\n",
    "                            \"이 나라는 와인으로 유명해\"})))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09646fce",
   "metadata": {},
   "source": [
    "# 5. 생성형 AI 평가: 나라명을 입력하면 그 나라의 제일 유명한 음식의 레시프를 출력하는 복합체인 구현\n",
    " - 위 : 나라설명->나라이름->수도 (체인두개 연결)\n",
    " - 나라이름 -> 그 나라에서 제일 유명한 음식 -> 레시피\n",
    " - exaone3.5:2.4b, llama3.1:405b(수능 언어영역 2위), llama3:70b(llama3.1:405b와 유사) llama3.2:3b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6d4e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 복합체인 : 나라명 -> 그 나라에서 제일 유명한 음식(food_chain)\n",
    "##                     음식 -> 레시피(recipe_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38a2c876",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.output_parsers import JsonOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "828c2880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "비빔밥은 한국의 대표적인 전통 음식 중 하나로, 다양한 재료들이 조화롭게 어우러져 풍부한 맛과 영양을 제공하는 요리입니다. 주요 구성 요소와 특징은 다음과 같습니다:\n",
      "\n",
      "### 주요 재료:\n",
      "1. **밥**: 보통 백미를 사용하지만, 건강을 위해 현미나 잡곡밥을 선택하기도 합니다.\n",
      "2. **주요 채소**:\n",
      "   - **시금치**: 신선하고 영양가가 높습니다.\n",
      "   - **당근**: 단맛과 함께 비타민 A가 풍부합니다.\n",
      "   - **파프리카**: 다양한 색상으로 시각적 매력과 비타민 C가 풍부합니다.\n",
      "   - **무**: 상큼한 맛과 식감을 더합니다.\n",
      "   - **오이**: 시원한 맛과 수분 공급에 좋습니다.\n",
      "3. **고기**:\n",
      "   - **소고기**: 주로 사용되며, 간장으로 양념합니다.\n",
      "   - **닭고기**: 저지방 고단백 식품으로 선택되기도 합니다.\n",
      "   - **두부**: 채식주의자를 위한 대안으로 인기가 있습니다.\n",
      "4. **기타 재료**:\n",
      "   - **고추장**: 매콤한 맛의 핵심 재료입니다.\n",
      "   - **간장**: 깊은 감칠맛을 더합니다.\n",
      "   - **참기름**: 고소한 풍미를 더합니다.\n",
      "   - **깨소금**: 약간의 소금과 함께 사용하여 맛을 균형 있게 맞춥니다.\n",
      "   - **김가루**: 고소한 풍미와 식감을 더합니다.\n",
      "\n",
      "### 조리 방법:\n",
      "1. **밥 준비**: 밥을 그릇에 담습니다.\n",
      "2. **고기 조리**: 선택한 고기를 간장과 고추장으로 양념하여 볶거나 익힙니다.\n",
      "3. **채소 준비**: 각 채소를 적당한 크기로 자르고 볶거나 살짝 데쳐서 준비합니다.\n",
      "4. **조합**: 밥 위에 준비한 고기와 채소들을 고루 얹습니다.\n",
      "5. **마무리**: 고추장 양념을 곁들여 비벼 먹습니다. 참기름과 깨소금을 뿌려 마무리합니다.\n",
      "\n",
      "비빔밥은 개인의 취향에 따라 재료를 조절할 수 있어 매우 유연하고 창의적인 요리입니다. 다양한 계절 재료를 활용하면 더욱 풍성한 맛을 즐길 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "food_chain = ChatOllama(model=\"exaone3.5:2.4b\",\n",
    "                temperature=0\n",
    "                )\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"{국가}에서 가장 유명한 음식 한가지만 답해. 음식명만 답해.\",\n",
    "    input_variables=[\"국가\"]\n",
    ")\n",
    "\n",
    "recipe_prompt = ChatOllama(model=\"exaone3.5:2.4b\",\n",
    "                temperature=0,\n",
    "                template=\"{음식}: 레시피를 알려줘\",\n",
    "                input_variables=[\"음식\"]\n",
    "                )\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "recipe_chain = prompt_template | food_chain | output_parser | recipe_prompt | output_parser\n",
    "\n",
    "print(recipe_chain.invoke({\"국가\":\"한국\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917d011f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527ad372",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm(ipykernel)",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "371.649px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
